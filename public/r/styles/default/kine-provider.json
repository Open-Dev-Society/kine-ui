{
  "name": "kine-provider",
  "type": "registry:component",
  "dependencies": [
    "@mediapipe/tasks-vision"
  ],
  "registryDependencies": [],
  "files": [
    {
      "path": "KineProvider.tsx",
      "content": "\"use client\";\r\n\r\nimport React, { createContext, useContext, useEffect, useRef, useState } from \"react\";\r\nimport { engine } from \"../core/kine-engine\";\r\nimport type { NormalizedLandmark } from \"@mediapipe/tasks-vision\";\r\n\r\ninterface KineContextType {\r\n    landmarksRef: React.MutableRefObject<NormalizedLandmark[][] | null>;\r\n    isWebcamActive: boolean;\r\n    webcamError: string | null;\r\n}\r\n\r\nconst KineContext = createContext<KineContextType>({\r\n    landmarksRef: { current: null },\r\n    isWebcamActive: false,\r\n    webcamError: null,\r\n});\r\n\r\nexport const useKine = () => useContext(KineContext);\r\n\r\ninterface KineProviderProps {\r\n    children: React.ReactNode;\r\n    showDebugVideo?: boolean;\r\n}\r\n\r\nexport const KineProvider: React.FC<KineProviderProps> = ({ children, showDebugVideo = false }) => {\r\n    const videoRef = useRef<HTMLVideoElement>(null);\r\n    const [isWebcamActive, setIsWebcamActive] = useState(false);\r\n    const [webcamError, setWebcamError] = useState<string | null>(null);\r\n    const landmarksRef = useRef<NormalizedLandmark[][] | null>(null);\r\n    const requestRef = useRef<number | null>(null);\r\n\r\n    useEffect(() => {\r\n        let stream: MediaStream | null = null;\r\n        let isUnmounted = false;\r\n        let lastVideoTime = -1;\r\n\r\n        const startWebcam = async () => {\r\n            try {\r\n                // Ensure no other tabs are hoarding the camera if possible on some browsers\r\n                stream = await navigator.mediaDevices.getUserMedia({\r\n                    video: { facingMode: \"user\" },\r\n                });\r\n\r\n                if (isUnmounted) {\r\n                    stream.getTracks().forEach((track) => track.stop());\r\n                    return;\r\n                }\r\n\r\n                if (videoRef.current) {\r\n                    videoRef.current.srcObject = stream;\r\n\r\n                    // Explicitly attempt to play to prevent frozen stream\r\n                    videoRef.current.onloadedmetadata = () => {\r\n                        videoRef.current?.play().catch(e => console.error(\"Play error:\", e));\r\n                    };\r\n\r\n                    videoRef.current.addEventListener(\"loadeddata\", async () => {\r\n                        try {\r\n                            await engine.initialize(videoRef.current!);\r\n                            if (isUnmounted) return;\r\n                            setIsWebcamActive(true);\r\n                            setWebcamError(null);\r\n                            detectFrame();\r\n                        } catch (initError) {\r\n                            console.error(\"MediaPipe initialization error:\", initError);\r\n                            setWebcamError(\"Failed to initialize gesture engine.\");\r\n                        }\r\n                    });\r\n                }\r\n            } catch (error: any) {\r\n                console.error(\"Error accessing webcam: \", error);\r\n                if (error.name === \"NotReadableError\") {\r\n                    setWebcamError(\"Camera is presently in use by another application or tab.\");\r\n                } else if (error.name === \"NotAllowedError\") {\r\n                    setWebcamError(\"Camera access was denied.\");\r\n                } else {\r\n                    setWebcamError(error.message || \"Failed to access webcam.\");\r\n                }\r\n            }\r\n        };\r\n\r\n        const detectFrame = () => {\r\n            if (isUnmounted) return;\r\n\r\n            // Standard MediaPipe optimization: Only detect if video frame has actually updated\r\n            if (videoRef.current && videoRef.current.currentTime !== lastVideoTime) {\r\n                lastVideoTime = videoRef.current.currentTime;\r\n\r\n                // Use strictly increasing timestamp\r\n                const result = engine.detectHands(performance.now());\r\n\r\n                if (result && result.landmarks && result.landmarks.length > 0) {\r\n                    landmarksRef.current = result.landmarks;\r\n                } else {\r\n                    landmarksRef.current = null;\r\n                }\r\n            }\r\n            requestRef.current = requestAnimationFrame(detectFrame);\r\n        };\r\n\r\n        startWebcam();\r\n\r\n        return () => {\r\n            isUnmounted = true;\r\n            if (stream) {\r\n                stream.getTracks().forEach((track) => track.stop());\r\n            }\r\n            if (requestRef.current !== null) {\r\n                cancelAnimationFrame(requestRef.current);\r\n            }\r\n        };\r\n    }, []);\r\n\r\n    return (\r\n        <KineContext.Provider value={{ landmarksRef, isWebcamActive, webcamError }}>\r\n            {/* Hidden (or debug) video element for MediaPipe processing */}\r\n            <video\r\n                ref={videoRef}\r\n                playsInline\r\n                muted\r\n                style={{\r\n                    display: showDebugVideo ? \"block\" : \"none\",\r\n                    position: \"fixed\",\r\n                    top: 0,\r\n                    right: 0,\r\n                    width: \"320px\",\r\n                    height: \"240px\",\r\n                    zIndex: 9999,\r\n                    transform: \"scaleX(-1)\", // Mirror the video for user interaction\r\n                }}\r\n            />\r\n            {children}\r\n        </KineContext.Provider>\r\n    );\r\n};\r\n",
      "type": "registry:component",
      "target": "components/kine/KineProvider.tsx"
    },
    {
      "path": "kine-engine.ts",
      "content": "import { FilesetResolver, HandLandmarker, HandLandmarkerResult } from \"@mediapipe/tasks-vision\";\r\n\r\nexport class KineEngine {\r\n  private static instance: KineEngine | null = null;\r\n  private handLandmarker: HandLandmarker | null = null;\r\n  private videoElement: HTMLVideoElement | null = null;\r\n  private isInitialized = false;\r\n\r\n  private constructor() {}\r\n\r\n  public static getInstance(): KineEngine {\r\n    if (!KineEngine.instance) {\r\n      KineEngine.instance = new KineEngine();\r\n    }\r\n    return KineEngine.instance;\r\n  }\r\n\r\n  public async initialize(videoElement: HTMLVideoElement) {\r\n    if (this.isInitialized) return;\r\n    this.videoElement = videoElement;\r\n\r\n    // Load Wasm files from unpkg/jsdelivr\r\n    const vision = await FilesetResolver.forVisionTasks(\r\n      \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm\"\r\n    );\r\n\r\n    // Initialize HandLandmarker\r\n    this.handLandmarker = await HandLandmarker.createFromOptions(vision, {\r\n      baseOptions: {\r\n        modelAssetPath:\r\n          \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\",\r\n        delegate: \"GPU\",\r\n      },\r\n      runningMode: \"VIDEO\",\r\n      numHands: 2,\r\n    });\r\n\r\n    this.isInitialized = true;\r\n  }\r\n\r\n  public detectHands(timeInMs: number): HandLandmarkerResult | null {\r\n    if (!this.handLandmarker || !this.videoElement || this.videoElement.readyState < 2) {\r\n      return null;\r\n    }\r\n    return this.handLandmarker.detectForVideo(this.videoElement, timeInMs);\r\n  }\r\n}\r\n\r\nexport const engine = KineEngine.getInstance();\r\n",
      "type": "registry:component",
      "target": "components/kine/kine-engine.ts"
    }
  ]
}